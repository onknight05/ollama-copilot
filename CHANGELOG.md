# Change Log

All notable changes to the "ollama-copilot" extension will be documented in this file.

## [0.0.1] - 2026-01-29

### Added
- Initial release of Ollama Copilot
- Inline code completion using Ollama models
- Interactive chat panel in VS Code sidebar
- Support for multiple Ollama models
- Configurable autocomplete settings (debounce, temperature, max tokens)
- Commands for toggling autocomplete and clearing chat
- Full local processing - no external API calls
- Support for all programming languages

### Features
- **Autocomplete**: Get AI-powered code suggestions as you type
- **Chat Interface**: Ask questions and get help directly in VS Code
- **Privacy-First**: All processing happens locally through Ollama
- **Customizable**: Configure models, endpoints, and behavior
- **Lightweight**: Minimal dependencies and resource usage
